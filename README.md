# What's Beyond the Accuracy of Code Models?

This GitHub repository is dedicated to curating a comprehensive collection of publications that focus on various aspects of code models beyond their accuracies. While accuracy is undoubtedly an essential factor in evaluating code models, there is a growing need to explore other dimensions that contribute to a model's overall effectiveness and applicability.

The aim of this repository is to shine a light on research that delves into areas such as robustness, interpretability, fairness, and other important criteria that can help improve the state of code models. By compiling these publications, we hope to provide a valuable resource for researchers and practitioners in the field of code modeling.


| Paper Title                                                    | Author      | Venue | Year | Topic         |
|----------------------------------------------------------------|-------------|-------|------|---------------|
| Adversarial Attacks against Binary Similarity Systems | Capozzi et al.  | ArXiV   | 2023 |  Robustness  |
| Discrete Adversarial Attack to Models of Code                 | Guo et al.  | PLDI  | 2023 | Robustness    |
| A comparative study of adversarial training methods for neural models of source code                 | Li et al.  | FGCS  | 2023 | Robustness    |
| Memorization and generalization in neural code intelligence models | Rabin et al.  | IST | 2023 | Memorization    |
| [CLAWSAT: Towards Both Robust and Accurate Code Models](https://arxiv.org/abs/2211.11711) | Jia et al.  | SANER | 2023 | Robustness    |
| [CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models](https://people.cs.vt.edu/~reddy/papers/AAAI23.pdf) | Jha et al.  | AAAI | 2023 | Robustness    |
| Poison Attack and Defense on Deep Source Code Processing Models | Li et al. | ArXiV | 2023 | Data Poisoning |
| [Stealthy Backdoor Attack for Code Models](https://arxiv.org/abs/2301.02496) | Yang et al. | ArXiV | 2023 | Data Poisoning |
| CoCoFuzzing: Testing Neural Code Models With Coverage-Guided Fuzzing | Wei et al.  | IEEE TR   | 2022 |  Robustness  |
| Generating Adversarial Source Programs Using Important Tokens-based Structural Transformations | Chen et al.  | ICECCS   | 2022 |  Robustness  |
| Towards Robust Models of Code via Energy-Based Learning on Auxiliary Datasets | Nghi et al.  | ASE   | 2022 |  Robustness  |
| [Compressing Pre-trained Models of Code into 3 MB](https://dl.acm.org/doi/abs/10.1145/3551349.3556964) | Shi et al.  | ASE   | 2022 | Model Compression |
| How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective | Yang et al.  | ArXiV   | 2022 |  Robustness  |
| Adversarial Robustness of Deep Code Comment Generation | Zhou et al.  | TOSEM   | 2022 |  Robustness  |
| You see what I want you to see: poisoning vulnerabilities in neural code search | Wan et al.  | FSE   | 2022 |  Data Poisoning  |
| Backdoors in neural models of source code | Ramakrishnan et al.  | ICPR   | 2022 |  Data Poisoning  |
| CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning | Sun et al.  | WWW   | 2022 |  Data Poisoning  |
| Semantic robustness of models of source code | Ramakrishnan et al. | SANER  | 2022 | Robustness    |
| Towards Robustness of Deep Program Processing Modelsâ€”Detection, Estimation, and Enhancement | Zhang et al. | TOSEM  | 2022 | Robustness    |
| RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation | Li et al. | ICSE  | 2022 | Robustness    |
| Counterfactual explanations for models of code | Cito et al. | ICSE  | 2022 | Explainability    |
| [Natural attack for pre-trained models of code](https://dl.acm.org/doi/abs/10.1145/3510003.3510146) | Yang et al. | ICSE  | 2022 | Robustness    |
| [Generating Adversarial Computer Programs using Optimized Obfuscations](https://openreview.net/forum?id=PH5PH9ZO_4) | Srikant et al. | ICLR | 2021 | Robustness    |
| Generating Adversarial Examples of Source Code Classification Models via Q-Learning-Based Markov Decision Process | Tian et al. | QRS | 2021 | Robustness    |
| Assessing robustness of ml-based program analysis tools using metamorphic program transformations | Applis et al. | ASE | 2021 | Robustness    |
| Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffee? | Nguyen et al.  | ASE   | 2021 | Data Poisoning |
| Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion | Schuster, et al.  | USENIX   | 2021 | Data Poisoning |
| On the generalizability of neural program models with respect to semantic-preserving program transformations | Rabin et al. | IST | 2021 | Robustness    |
| A search-based testing framework for deep neural networks of source code embedding | Pour et al. | ICST | 2021 | Robustness    |
| Deceiving neural source code classifiers: finding adversarial examples with grammatical evolution | Springer et al. | KDD workshop | 2021 | Robustness    |
| Deceiving neural source code classifiers: finding adversarial examples with grammatical evolution | Ferretti et al. | GECCO | 2021 | Robustness    |
| Generating Adversarial Examples for Holding Robustness of Source Code Processing Models | Zhang et al. | AAAI  | 2020 | Robustness    |
| Adversarial Robustness for Code | Bielik et al. | ICML  | 2020 | Robustness    |
| Adversarial examples for models of code | Yefet et al. | OOPSLA  | 2020 | Robustness    |


## Acronyms

- ICSE: The IEEE/ACM International Conference on Software Engineering
- FSE: The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering
- ASE: The IEEE/ACM International Conference on Automated Software Engineering
- SANER: The IEEE International Conference on. Software Analysis, Evolution and Reengineering
- ICLR: The International Conference on Learning Representations

# Contribution

Currently, the repository is maintained by [YANG Zhou](https://yangzhou6666.github.io).

We welcome contributions from the community in the form of additional publications, topic suggestions, and any other resources that can enrich this repository. Together, let's work towards advancing the field of code modeling by focusing on aspects beyond accuracy.
