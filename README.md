# What's Beyond the Accuracy of Code Models?

This GitHub repository is dedicated to curating a comprehensive collection of publications that focus on various aspects of code models beyond their accuracies. While accuracy is undoubtedly an essential factor in evaluating code models, there is a growing need to explore other dimensions that contribute to a model's overall effectiveness and applicability.

The aim of this repository is to shine a light on research that delves into areas such as robustness, interpretability, fairness, and other important criteria that can help improve the state of code models. By compiling these publications, we hope to provide a valuable resource for researchers and practitioners in the field of code modeling.


| Paper Title                                                    | Author      | Venue | Year | Topic         |
|----------------------------------------------------------------|-------------|-------|------|---------------|
| Discrete Adversarial Attack to Models of Code                 | Guo et al.  | PLDI  | 2023 | Robustness    |
| [CLAWSAT: Towards Both Robust and Accurate Code Models](https://arxiv.org/abs/2211.11711) | Jia et al.  | SANER | 2023 | Robustness    |
| [CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming Language Models](https://people.cs.vt.edu/~reddy/papers/AAAI23.pdf) | Jha et al.  | AAAI | 2023 | Robustness    |
| Poison Attack and Defense on Deep Source Code Processing Models | Li et al. | ArXiV | 2023 | Data Poisoning |
| [Stealthy Backdoor Attack for Code Models](https://arxiv.org/abs/2301.02496) | Yang et al. | ArXiV | 2023 | Data Poisoning |
| CoCoFuzzing: Testing Neural Code Models With Coverage-Guided Fuzzing | Wei et al.  | IEEE TR   | 2022 |  Robustness  |
| You see what I want you to see: poisoning vulnerabilities in neural code search | Wan et al.  | FSE   | 2022 |  Data Poisoning  |
| Backdoors in neural models of source code | Ramakrishnan et al.  | ICPR   | 2022 |  Data Poisoning  |
| [Compressing Pre-trained Models of Code into 3 MB](https://dl.acm.org/doi/abs/10.1145/3551349.3556964) | Shi et al.  | ASE   | 2022 | Model Compression |
| Semantic robustness of models of source code | Ramakrishnan et al. | SANER  | 2022 | Robustness    |
| [Natural attack for pre-trained models of code](https://dl.acm.org/doi/abs/10.1145/3510003.3510146) | Yang et al. | ICSE  | 2022 | Robustness    |
| [Generating Adversarial Computer Programs using Optimized Obfuscations](https://openreview.net/forum?id=PH5PH9ZO_4) | Srikant et al. | ICLR | 2021 | Robustness    |
| Assessing robustness of ml-based program analysis tools using metamorphic program transformations | Applis et al. | ASE | 2021 | Robustness    |
| Adversarial Attacks to API Recommender Systems: Time to Wake Up and Smell the Coffee? | Nguyen et al.  | ASE   | 2021 | Data Poisoning |
| Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion | Schuster, et al.  | USENIX   | 2021 | Data Poisoning |
| On the generalizability of neural program models with respect to semantic-preserving program transformations | Rabin et al. | IST | 2021 | Robustness    |
| A search-based testing framework for deep neural networks of source code embedding | Pour et al. | ICST | 2021 | Robustness    |
| Generating Adversarial Examples for Holding Robustness of Source Code Processing Models | Zhang et al. | AAAI  | 2020 | Robustness    |
| Adversarial examples for models of code | Yefet et al. | OOPSLA  | 2020 | Robustness    |


## Acronyms

- ICSE: The IEEE/ACM International Conference on Software Engineering
- FSE: The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering
- ASE: The IEEE/ACM International Conference on Automated Software Engineering
- SANER: The IEEE International Conference on. Software Analysis, Evolution and Reengineering
- ICLR: The International Conference on Learning Representations

# Contribution
We welcome contributions from the community in the form of additional publications, topic suggestions, and any other resources that can enrich this repository. Together, let's work towards advancing the field of code modeling by focusing on aspects beyond accuracy.
